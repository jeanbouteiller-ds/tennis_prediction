{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM/P/N2mDxd0MP2B/VkyIEr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeanbouteiller-ds/tennis_prediction/blob/main/workflow_notebooks/merge_tables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package_name):\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package_name])\n",
        "        print(f\"Successfully installed {package_name}\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(f\"Failed to install {package_name}\") # Install the PyGitHub library\n",
        "\n",
        "install_package(\"requests\")\n",
        "install_package(\"PyGitHub\")\n",
        "install_package(\"pandas\")\n",
        "install_package(\"tqdm\")\n",
        "install_package(\"mumpy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBnT4oD2GAI7",
        "outputId": "d5994b34-83dc-4426-81e0-d9ba8bee4461"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed requests\n",
            "Successfully installed PyGitHub\n",
            "Successfully installed pandas\n",
            "Successfully installed tqdm\n",
            "Failed to install mumpy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7w9-KyhTAtX",
        "outputId": "cf0b4a89-0fc8-427e-dbd1-fbea0761b5e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed requests\n",
            "Successfully installed requests\n",
            "Successfully installed PyGitHub\n",
            "Successfully installed pandas\n",
            "Successfully installed requests\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import io\n",
        "import importlib.util\n",
        "import sys\n",
        "import nbformat\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "\n",
        "# Define the URL of the nb1 notebook on GitHub\n",
        "github_url = \"https://raw.githubusercontent.com/jeanbouteiller-ds/tennis_prediction/main/functions/functions_fixed_table.ipynb\"\n",
        "\n",
        "# Download the notebook as a raw .ipynb file\n",
        "response = requests.get(github_url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "  notebook_content = response.text\n",
        "\n",
        "  # Parse the notebook content\n",
        "  notebook = nbformat.reads(notebook_content, as_version=4)\n",
        "\n",
        "  # Now you can execute the cells in the notebook\n",
        "  for cell in notebook.cells:\n",
        "      if cell.cell_type == 'code':\n",
        "          exec(cell.source)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_matchs=get_file_content('data/clean_datasets/df_matchs_clean.csv')\n",
        "df_ranking=get_file_content('data/clean_datasets/df_ranking_clean.csv')\n",
        "df_betting=get_file_content('data/clean_datasets/df_betting_clean.csv')\n",
        "df_fixed_table=get_file_content('data/clean_datasets/df_fixed_table_clean.csv')\n",
        "df_tournaments=get_file_content('data/clean_datasets/df_tournaments_clean.csv')"
      ],
      "metadata": {
        "id": "97tsMuUrZXSb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add Player Ranking"
      ],
      "metadata": {
        "id": "4NF04tbqLBbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert date columns to datetime if they are not already\n",
        "df_matchs['tournament_date'] = pd.to_datetime(df_matchs['tournament_date'])\n",
        "df_ranking['date'] = pd.to_datetime(df_ranking['date'])\n",
        "\n",
        "\n",
        "# Merge based on the closest date before tournament_date to find_winner_raking\n",
        "df_ranking['winner_name_clean_3first'] = df_ranking['player_name_clean_3first']\n",
        "merged_data_winner = pd.merge_asof(df_matchs.sort_values('tournament_date'),\n",
        "                            df_ranking.sort_values('date'),\n",
        "                            by=['winner_name_clean_3first'],\n",
        "                            left_on='tournament_date',\n",
        "                            right_on='date',\n",
        "                            direction='backward')\n",
        "\n",
        "merged_data_winner.rename(columns={'ranking': 'ranking_winner'}, inplace=True)\n",
        "final_df=merged_data_winner.drop([\"player_name\",\"date\",\"player_name_clean_3first\"],axis=1)\n",
        "\n",
        "# Merge based on the closest date before tournament_date to fin loser_ranking\n",
        "df_ranking=df_ranking.drop('winner_name_clean_3first',axis=1)\n",
        "df_ranking['loser_name_clean_3first'] = df_ranking['player_name_clean_3first']\n",
        "merged_data_loser = pd.merge_asof(final_df.sort_values('tournament_date'),\n",
        "                            df_ranking.sort_values('date'),\n",
        "                            by=['loser_name_clean_3first'],\n",
        "                            left_on='tournament_date',\n",
        "                            right_on='date',\n",
        "                            direction='backward')\n",
        "\n",
        "# Rename the 'ranking' column from df_ranking to 'ranking_winner'\n",
        "merged_data_loser.rename(columns={'ranking': 'ranking_loser'}, inplace=True)\n",
        "\n",
        "# Now, merged_data contains the desired dataset\n",
        "df_all_with_ranking=merged_data_loser.drop([\"tournament_name\",\"player_name\",\"date\",\"player_name_clean_3first\"],axis=1)"
      ],
      "metadata": {
        "id": "L2rKxhuKKQUf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add odds\n",
        "\n",
        "The code below takes a bit of time to run :)"
      ],
      "metadata": {
        "id": "m04XoYVnR1Ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Merge based on the conditions\n",
        "merged_data = df_all_with_ranking.merge(\n",
        "    df_betting[['unique_tournament_id','clean_winner_only_name_full','clean_loser_only_name_full',\n",
        "                'Final_odd_winner','Final_odd_loser']],\n",
        "    how='left',\n",
        "    left_on=['unique_tournament_id'],\n",
        "    right_on=['unique_tournament_id']\n",
        ")\n",
        "\n",
        "merged_data[\"unique_game_id\"]=merged_data['winner_name']+\"//\"+merged_data['loser_name']+\"//\"+merged_data[\"unique_tournament_id\"]\n",
        "\n",
        "condition1 = merged_data.apply(lambda row: str(row['clean_loser_only_name_full']) in str(row['loser_name']), axis=1)\n",
        "condition2 = merged_data.apply(lambda row: str(row['clean_winner_only_name_full']) in str(row['winner_name']), axis=1)\n",
        "\n",
        "df_ranking_odds = merged_data[condition1 & condition2].drop_duplicates(\"unique_game_id\")\n",
        "no_odds_games=merged_data[(~merged_data['unique_game_id'].isin(df_ranking_odds['unique_game_id'].unique()))].drop_duplicates(\"unique_game_id\")\n",
        "no_odds_games['clean_winner_only_name_full']=math.nan\n",
        "no_odds_games['clean_loser_only_name_full']=math.nan\n",
        "no_odds_games['Final_odd_winner']=math.nan\n",
        "no_odds_games['Final_odd_loser']=math.nan\n",
        "df_ranking_odds= pd.concat([df_ranking_odds,no_odds_games])\n",
        "df_ranking_odds\n",
        "# df_ranking_odds = pd.concat(merged_data)\n",
        "# Now, merged_data contains the rows where all three conditions are met (based on inclusion)\n"
      ],
      "metadata": {
        "id": "oVEeywsyL5ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add Df Fixed Data"
      ],
      "metadata": {
        "id": "rkwbPBf9RtGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Merge based on winner_name_clean_3first\n",
        "merged_data = df_ranking_odds.merge(\n",
        "    df_fixed_table,  # Replaced 'df_fixed' with 'df_fixed_table'\n",
        "    left_on='winner_name_clean_3first',\n",
        "    right_on='player_name_clean_3first',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Rename columns from df_fixed_table with 'winner:' prefix\n",
        "for col in df_fixed_table.columns:\n",
        "    merged_data.rename(columns={col: 'winner: ' + col}, inplace=True)\n",
        "\n",
        "# Drop the original 'player_name_clean_3first' column\n",
        "merged_data.drop('winner: player_name_clean_3first', axis=1, inplace=True)\n",
        "\n",
        "# Merge again based on loser_name_clean_3first\n",
        "merged_data = merged_data.merge(\n",
        "    df_fixed_table,  # Replaced 'df_fixed' with 'df_fixed_table'\n",
        "    left_on='loser_name_clean_3first',\n",
        "    right_on='player_name_clean_3first',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Rename columns from df_fixed_table with 'loser:' prefix\n",
        "for col in df_fixed_table.columns:\n",
        "    merged_data.rename(columns={col: 'loser: ' + col}, inplace=True)\n",
        "\n",
        "# Drop the original 'player_name_clean_3first' columns\n",
        "merged_data.drop(['loser: player_name_clean_3first', 'winner_name_clean_3first', 'loser_name_clean_3first',\n",
        "                  ], axis=1, inplace=True)\n",
        "\n",
        "# Now, merged_data contains the desired columns with 'winner:' and 'loser:' prefixes\n",
        "df_ranking_odds_fixed=merged_data.copy()"
      ],
      "metadata": {
        "id": "jRI__QC7P9ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add tournaments Data"
      ],
      "metadata": {
        "id": "uMwt8uPeTXjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_ranking_odds_fixed_tournament=df_ranking_odds_fixed.merge(df_tournaments,left_on=\"unique_tournament_id\",right_on=\"unique_tournament_id\").drop(\"tournament_date_y\",axis=1).rename({\"tournament_date_x\":\"tournament_date\"},axis=1)\n"
      ],
      "metadata": {
        "id": "WMbDqtBVbzVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the binary_transformation with train,validation & test separation"
      ],
      "metadata": {
        "id": "7Cx8ibdbmqgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(seed=42)\n",
        "df_ranking_odds_fixed_tournament['winner'] = np.random.randint(2, size=len(df_ranking_odds_fixed_tournament))\n",
        "add_file_github('data/clean_datasets/df_all_merged.csv',df_ranking_odds_fixed_tournament.to_csv(index=False))\n",
        "\n",
        "df=df_ranking_odds_fixed_tournament.copy()[['tournament_date','unique_game_id']]\n",
        "\n",
        "# Convert 'tournament_date' to datetime if it's not already in datetime format\n",
        "df['tournament_date'] = pd.to_datetime(df['tournament_date'])\n",
        "\n",
        "# Split the dataset based on date ranges\n",
        "train = df[df['tournament_date'].dt.year <= 2017].drop(['tournament_date'],axis=1).drop_duplicates(\"unique_game_id\")\n",
        "validation = df[(df['tournament_date'].dt.year >= 2018) & (df['tournament_date'].dt.year <= 2020)].drop(['tournament_date'],axis=1).drop_duplicates(\"unique_game_id\")\n",
        "test = df[(df['tournament_date'].dt.year >= 2021) & (df['tournament_date'].dt.year <= 2023)].drop(['tournament_date'],axis=1).drop_duplicates(\"unique_game_id\")\n"
      ],
      "metadata": {
        "id": "zbFOKYyXmyVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_file_github('data/ml_datasets/train_games_ids.csv',train.to_csv(index=False))\n",
        "add_file_github('data/ml_datasets/validation_games_ids.csv',validation.to_csv(index=False))\n",
        "add_file_github('data/ml_datasets/test_games_ids.csv',test.to_csv(index=False))"
      ],
      "metadata": {
        "id": "NioKgMQmpaa7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}